{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Data Object`\n",
    "This notebook is used for authoring a dataset class that can be used for loading, partioning and returning data useful for infernence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.stats as stats\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PricingWizardDataset:\n",
    "    def __init__(self,\n",
    "                 *,\n",
    "                 filename:str = \"post_preprocessing_without_dummies.csv\",\n",
    "                 alternative_data_path:str = None,\n",
    "                 train_size:int = .8,\n",
    "                 test_size:int = .2,\n",
    "                 ramdom_state = 42,\n",
    "                 outlier_removal = True) -> None:\n",
    "        \"\"\"\n",
    "        Data extraction and partioning class.\n",
    "\n",
    "        Class for extracting Trendsales data for modeling in Pricing Wizards exam Project. The class should simplify the process of passing data to models.\n",
    "\n",
    "        Args:\n",
    "            filename (str, optional): Filename from subfolder to load. Defaults to post_preprocessing_without_dummies\n",
    "            alternative_path (str, optional): In case an alternative path is prefered, such can be called. Defaults to None.\n",
    "            train_size (float, optional): Portion of dataset to include in train split. Defaults to .8 or 80% of data.\n",
    "            test_size (float, optional): Portion of dataset to include in test split. This subset will per default be a holdout dataset, and should only be used for final model performance. \n",
    "                                         Validation subsetes will be extracted from the training set. This ensures sufficient large test set. Defaults to .2 or 20% of data.\n",
    "            random_state = (int, optional): Controls the behaviour of shuffling applied to the data before applying the split. Enables reproducibaility of resutls across multiple initalizations. Defaults to 42.\n",
    "            \n",
    "        \n",
    "        Attributes:\n",
    "            data_directory (str): Full path to subdirectory storing data \n",
    "            filename (str): Name of data csv file to be extracted\n",
    "            seed (int): Seed for reproducability\n",
    "\n",
    "        Methods:\n",
    "            __call__: Calling object after initalization will return partitioned dataset, in X_train, X_test, Y_train, Y_test format.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Data storage details\n",
    "        if alternative_data_path:\n",
    "            self.data_folder = alternative_data_path\n",
    "        else:\n",
    "            # Control the working directories are correct\n",
    "            assert 'pricing_wizards' in os.getcwd(), f\"This program can only be executed inside the pricing_wizards directory if no alternative data path is specified. You're currently in {os.getcwd()}. Please change directory into pricing wizards before you calling class or specify an alternative data path.\"\n",
    "            \n",
    "            self.data_folder = os.path.join(os.getcwd().split('pricing_wizards')[0],'pricing_wizards/data/')\n",
    "        \n",
    "        # Name of data file\n",
    "        self.filename = filename + '.csv' if '.csv' not in filename else filename\n",
    "        \n",
    "        # Asserting file exists in data folder\n",
    "        assert self.filename in os.listdir(self.data_folder), f'File, {self.filename}.csv, does not appear in data folder, {self.data_folder}. Please make sure the correct filename and data folder is specified. {os.listdir(self.data_folder)}'\n",
    "        \n",
    "        # Seed for reproducability\n",
    "        self.seed = ramdom_state\n",
    "        np.random.seed(self.seed)\n",
    "        \n",
    "    \n",
    "        # Splitting details\n",
    "        self.train_size = train_size\n",
    "        self.test_size = test_size\n",
    "        \n",
    "        # If None is not passed as argument\n",
    "        if not self.train_size:\n",
    "            assert self.train_size + self.test_size + self.val_size == 1, \"Sum of split sizes must equal 1. Ensure passed size arguments is equal to 1\"\n",
    "            \n",
    "\n",
    "        # Loading data\n",
    "        self.__load__()\n",
    "        \n",
    "        # Outlier Removal, if specified\n",
    "        if outlier_removal: \n",
    "            self.delete_outliers()\n",
    "        \n",
    "        self.outlier_removed = outlier_removal\n",
    "\n",
    "        # UX Feedback\n",
    "        self.__repr = f'Dataset Loaded: {self.filename.rstrip(\".csv\")}\\n\\tNumber of Rows: {len(self.df)}\\n\\tOutlier Removal: {self.outlier_removed}\\n\\tTrain Size: {self.train_size}\\n\\tTest Size: {self.test_size}\\n\\tRandom State: {self.seed}'\n",
    "        print(self.__repr)\n",
    "    \n",
    "    def __load__(self):\n",
    "        \"\"\"Internal class method for loading data from data folder\"\"\"\n",
    "        \n",
    "        # Loading data using pandas\n",
    "        self.df = pd.read_csv(f'{self.data_folder}{self.filename}')\n",
    "        \n",
    "        # Fill null brand values with Unassigned\n",
    "        self.df.brand_name = self.df.brand_name.fillna('Unassigned')\n",
    "    \n",
    "    def delete_outliers(self):\n",
    "        \"\"\"\n",
    "        Method for removing outliers. \n",
    "        \n",
    "        Method used is a IQR performed on a logscaled version of the listing price. Using a logscaled listing price version helps seperate brand listings prices in regards to both upper and lower bounds.\n",
    "        This method will overwrite the df class attribute with the a dataset that does not have any outliers. The original dataset will be assigned `self.raw_df`.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Generating dataset copy\n",
    "        data = self.df.copy()\n",
    "        \n",
    "        # Logscaled Listing Price\n",
    "        data['log_price'] = np.log(data['listing_price']) \n",
    "        \n",
    "        # Assigning Unassigned to nulls\n",
    "        data.brand_name = data.brand_name.fillna('Unassigned')\n",
    "        \n",
    "        # Computing qunatiles on brandlevel\n",
    "        iqr_brand = data.groupby('brand_name').agg(q25 = ('log_price', lambda x: x.quantile(.25)),\n",
    "                                                      q75 = ('log_price', lambda x: x.quantile(.75))).reset_index()\n",
    "\n",
    "        # Computing difference and thresholds\n",
    "        iqr_brand = iqr_brand.assign(\n",
    "            difference = lambda x: x.q75 - x.q25,\n",
    "            upper_bound = lambda x: x.q75 + 2*(x.difference), # Usually it is 1.5*(q3-q1), but given the nature of this dataset, the thresholds have been increased to make it less discriminative\n",
    "            lower_bound = lambda x: x.q25 - 2*(x.difference))\n",
    "\n",
    "        # Merge listings with brand quantile bounds\n",
    "        data  = data[['classified_id','log_price','brand_name']].merge(iqr_brand, on='brand_name',how='left')     \n",
    "        \n",
    "        # Determine if listing is outlier\n",
    "        self.df['outlier'] = (data.log_price > data.upper_bound) | (data.log_price < data.lower_bound)\n",
    "        \n",
    "        # Created raw df attribute before deleting rows (including outlier column)\n",
    "        self.raw_df = self.df.copy()\n",
    "        \n",
    "        # Overwriting df attribute\n",
    "        self.df = self.df[self.df.outlier == False]\n",
    "    \n",
    "    \n",
    "    def stratify_train_test_split(self, \n",
    "                                  val_size=.2,\n",
    "                                  split_based_on_original_size = True):\n",
    "        \"\"\"\n",
    "        Method for splitting data into train, test and validation subsets.\n",
    "        \n",
    "        Args:\n",
    "            val_size (float, optional): Specifies the proportion of the dataset that should be saved for validation. Defaults to .2.\n",
    "            split_based_on_original_size (bool, optional): Specifies wether val_size is based on original dataset size or for training size. If True, the validation split will equal 20% of the original dataset size. Defaults to True.\n",
    "        \n",
    "        Return:\n",
    "        (X_train, X_test, X_val), (y_train, y_test, y_val)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Lambda function for computing bins for listing prices\n",
    "        bins = lambda x: pd.cut(x, 4)\n",
    "        \n",
    "        # Train test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.df.drop(columns='listing_price'), \n",
    "                                                            self.df.listing_price.to_numpy(), \n",
    "                                                            stratify=bins(self.df.listing_price),\n",
    "                                                            train_size=self.train_size,\n",
    "                                                            test_size=self.test_size, \n",
    "                                                            random_state=self.seed)\n",
    "        # Train val split\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train,\n",
    "                                                          y_train,\n",
    "                                                          stratify=bins(y_train),\n",
    "                                                          test_size=val_size/self.train_size if split_based_on_original_size else val_size,\n",
    "                                                          random_state=self.seed)\n",
    "        \n",
    "        # Perform KS Test\n",
    "        equally_distributed_subsets = self.__ks_test__(y_train, y_test, y_val, alpha=.05)\n",
    "        \n",
    "        if not equally_distributed_subsets: \n",
    "            warnings.warn('Warning..... KS test for subsets failed. Distribution of splits are different')\n",
    "        else:\n",
    "            print('Dependent variable distribution is equal across all subsets')\n",
    "        \n",
    "        return X_train, X_test, X_val, y_train, y_test, y_val\n",
    "    \n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return self.__repr\n",
    "    \n",
    "    def __ks_test__(self, train, test, val, alpha=.05) -> bool:\n",
    "        \"\"\"Internal class method for Kolmogorov-Smirnov test. Used to evaluate if distributions in train, test and val are similar. Shoud return true if stratifeid split worked as intendede\"\"\"\n",
    "        \n",
    "        # Perform Kolmogorov-Smirnov for all splits\n",
    "        _, train_val = stats.ks_2samp(train, val)\n",
    "        _, test_val = stats.ks_2samp(test, val)\n",
    "        _, train_test = stats.ks_2samp(test, train)\n",
    "\n",
    "        # Return boolean value of wether or not all values are 3 or not\n",
    "        return sum([alpha < p_val for p_val in [train_val, test_val, train_test]]) == 3\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded: post_preprocessing_without_dummie\n",
      "\tNumber of Rows: 284660\n",
      "\tOutlier Removal: True\n",
      "\tTrain Size: 0.8\n",
      "\tTest Size: 0.2\n",
      "\tRandom State: 42\n"
     ]
    }
   ],
   "source": [
    "data = PricingWizardDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependent variable distribution is equal across all subsets\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, X_val, y_train, y_test, y_val = data.stratify_train_test_split(val_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading from utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    from utils.Dataloader import *\n",
    "except ImportError:\n",
    "    os.chdir('..')\n",
    "    from utils.Dataloader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded: post_preprocessing_without_dummie\n",
      "\tNumber of Rows: 284660\n",
      "\tOutlier Removal: True\n",
      "\tTrain Size: 0.8\n",
      "\tTest Size: 0.2\n",
      "\tRandom State: 42\n"
     ]
    }
   ],
   "source": [
    "data = PricingWizardDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependent variable distribution is equal across all subsets\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, X_val, y_train, y_test, y_val = data.stratify_train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
