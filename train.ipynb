{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "This is just a notebook version of the train.py file. Use this to ensure training works as intended\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Import\n",
    "import pandas as pd\n",
    "from utils.Dataloader import PricingWizardDataset\n",
    "from utils.DataTransformation import base_regression_pipeline, ridge_regression_pipeline\n",
    "from utils.helpers import save_model, drop_helpers\n",
    "from models import base_linear_regression, regularized_regression, regression_neural_network \n",
    "import argparse\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded: post_preprocessing_without_dummies\n",
      "\tNumber of Rows: 283055\n",
      "\tNumber of Columns: 22\n",
      "\tOutlier Removal: True\n",
      "\tTrain Size: 0.8\n",
      "\tTest Size: 0.2\n",
      "\tRandom State: 42\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = PricingWizardDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying data preparation...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# 1. Data transformations\n",
    "print('Applying data preparation...')    \n",
    "data.apply_function(base_regression_pipeline)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependent variable distribution is equal across all subsets\n"
     ]
    }
   ],
   "source": [
    "# 2. Stratify Split\n",
    "data.stratify_train_test_split(y_column='log_listing_price', \n",
    "                               val_size=0,\n",
    "                               return_splits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results:\n",
      "R2 Score: 0.5452212770709474\n",
      "MSE: 0.4381693860784058\n",
      "MAE 0.5134875030165035\n",
      "RMSE 0.6619436426754213\n"
     ]
    }
   ],
   "source": [
    "# 3. Train model\n",
    "results = linear_regression(data)\n",
    "\n",
    "# 4. Print results\n",
    "print('Test Results:')\n",
    "print('R2 Score:', results['r2'])\n",
    "print('MSE:', results['mse'])\n",
    "print('MAE', results['mae'])\n",
    "print('RMSE', results['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularizated Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying data preparation...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Reset Dataset\n",
    "data.reset_dataset()\n",
    "\n",
    "# 1. Data transformations\n",
    "print('Applying data preparation...')    \n",
    "data.apply_function(ridge_regression_pipeline)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependent variable distribution is equal across all subsets\n"
     ]
    }
   ],
   "source": [
    "# 2. Stratify Split\n",
    "data.stratify_train_test_split(y_column='log_listing_price', \n",
    "                               val_size=0,\n",
    "                               return_splits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model using GridSearchCV: regularized_regression\n",
      "Fitting 5 folds for each of 13 candidates, totalling 65 fits\n",
      "[CV] END ........................alpha=0.0031622776601683794; total time=  30.5s\n",
      "[CV] END ........................alpha=0.0031622776601683794; total time=  30.4s\n",
      "[CV] END ........................................alpha=0.001; total time=  30.6s\n",
      "[CV] END .........................................alpha=0.01; total time=  30.9s\n",
      "[CV] END .........................................alpha=0.01; total time=  31.3s\n",
      "[CV] END ........................alpha=0.0031622776601683794; total time=  31.3s\n",
      "[CV] END ........................................alpha=0.001; total time=  31.3s\n",
      "[CV] END ........................................alpha=0.001; total time=  31.5s\n",
      "[CV] END ........................................alpha=0.001; total time=  31.7s\n",
      "[CV] END ........................alpha=0.0031622776601683794; total time=  31.7s\n",
      "[CV] END ........................alpha=0.0031622776601683794; total time=  31.4s\n",
      "[CV] END ........................................alpha=0.001; total time=  31.9s\n",
      "[CV] END .........................................alpha=0.01; total time=  25.6s\n",
      "[CV] END .........................................alpha=0.01; total time=  27.8s\n",
      "[CV] END ..........................alpha=0.03162277660168379; total time=  28.1s\n",
      "[CV] END ..........................................alpha=0.1; total time=  28.2s\n",
      "[CV] END ..........................alpha=0.03162277660168379; total time=  28.1s\n",
      "[CV] END .........................................alpha=0.01; total time=  28.7s\n",
      "[CV] END ..........................alpha=0.03162277660168379; total time=  29.0s\n",
      "[CV] END ..........................alpha=0.03162277660168379; total time=  29.1s\n",
      "[CV] END ..........................................alpha=0.1; total time=  29.1s\n",
      "[CV] END ..........................alpha=0.03162277660168379; total time=  29.4s\n",
      "[CV] END ..........................................alpha=0.1; total time=  29.4s\n",
      "[CV] END ..........................................alpha=0.1; total time=  29.6s\n",
      "[CV] END ..........................................alpha=0.1; total time=  25.9s\n",
      "[CV] END ..........................alpha=0.31622776601683794; total time=  27.3s\n",
      "[CV] END ..........................alpha=0.31622776601683794; total time=  27.3s\n",
      "[CV] END ..........................alpha=0.31622776601683794; total time=  27.1s\n",
      "[CV] END ..........................................alpha=1.0; total time=  26.7s\n",
      "[CV] END ..........................alpha=0.31622776601683794; total time=  27.2s\n",
      "[CV] END ..........................alpha=0.31622776601683794; total time=  27.2s\n",
      "[CV] END ..........................................alpha=1.0; total time=  26.8s\n",
      "[CV] END ...........................alpha=3.1622776601683795; total time=  26.6s\n",
      "[CV] END ..........................................alpha=1.0; total time=  26.8s\n",
      "[CV] END ..........................................alpha=1.0; total time=  26.8s\n",
      "[CV] END ..........................................alpha=1.0; total time=  27.0s\n",
      "[CV] END ...........................alpha=3.1622776601683795; total time=  25.9s\n",
      "[CV] END ...........................alpha=3.1622776601683795; total time=  19.6s\n",
      "[CV] END .........................................alpha=10.0; total time=  26.4s\n",
      "[CV] END .........................................alpha=10.0; total time=  26.4s\n",
      "[CV] END ...........................alpha=3.1622776601683795; total time=  26.7s\n",
      "[CV] END ...........................alpha=3.1622776601683795; total time=  26.7s\n",
      "[CV] END ...........................alpha=31.622776601683793; total time=  26.5s\n",
      "[CV] END ...........................alpha=31.622776601683793; total time=  26.3s\n",
      "[CV] END ...........................alpha=31.622776601683793; total time=  27.3s\n",
      "[CV] END .........................................alpha=10.0; total time=  27.7s\n",
      "[CV] END .........................................alpha=10.0; total time=  27.6s\n",
      "[CV] END .........................................alpha=10.0; total time=  27.8s\n",
      "[CV] END ...........................alpha=31.622776601683793; total time=  24.9s\n",
      "[CV] END ...........................alpha=31.622776601683793; total time=  25.2s\n",
      "[CV] END ........................................alpha=100.0; total time=  25.4s\n",
      "[CV] END ...........................alpha=316.22776601683796; total time=  26.5s\n",
      "[CV] END ...........................alpha=316.22776601683796; total time=  26.6s\n",
      "[CV] END ........................................alpha=100.0; total time=  27.8s\n",
      "[CV] END ...........................alpha=316.22776601683796; total time=  27.7s\n",
      "[CV] END ...........................alpha=316.22776601683796; total time=  27.8s\n",
      "[CV] END ........................................alpha=100.0; total time=  28.2s\n",
      "[CV] END ........................................alpha=100.0; total time=  28.8s\n",
      "[CV] END ........................................alpha=100.0; total time=  28.7s\n",
      "[CV] END ...........................alpha=316.22776601683796; total time=  28.7s\n",
      "[CV] END .......................................alpha=1000.0; total time=  21.3s\n",
      "[CV] END .......................................alpha=1000.0; total time=  21.6s\n",
      "[CV] END .......................................alpha=1000.0; total time=   6.2s\n",
      "[CV] END .......................................alpha=1000.0; total time=   8.0s\n",
      "[CV] END .......................................alpha=1000.0; total time=   6.4s\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "results = regularized_regression(data, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results:\n",
      "R2 Score: 0.5695965129992877\n",
      "MSE: 0.4146843776034087\n",
      "MAE 0.4972702697816776\n",
      "RMSE 0.6439599192522845\n"
     ]
    }
   ],
   "source": [
    "# 4. Print results\n",
    "print('Test Results:')\n",
    "print('R2 Score:', results['r2'])\n",
    "print('MSE:', results['mse'])\n",
    "print('MAE', results['mae'])\n",
    "print('RMSE', results['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying data preparation...\n"
     ]
    }
   ],
   "source": [
    "# Reset dataset\n",
    "data.reset_dataset()\n",
    "\n",
    "# Apply ridge regression data preparation\n",
    "print('Applying data preparation...')    \n",
    "data.apply_function(ridge_regression_pipeline)\n",
    "    \n",
    "# Standard Scaling\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(drop_helpers(data.df))\n",
    "\n",
    "    \n",
    "# Assigning X to data.df\n",
    "data.df[drop_helpers(data.df).columns] = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependent variable distribution is equal across all subsets\n"
     ]
    }
   ],
   "source": [
    "# Split data   \n",
    "data.stratify_train_test_split(y_column='log_listing_price', \n",
    "                               val_size=.2,\n",
    "                               return_splits=False)\n",
    "\n",
    "# Converting to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(drop_helpers(data.X_train).to_numpy(), dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(drop_helpers(data.X_test).to_numpy(), dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(drop_helpers(data.X_val).to_numpy(), dtype=torch.float32)\n",
    "\n",
    "y_train_tensor = torch.tensor(data.y_train, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(data.y_test, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(data.y_val, dtype=torch.float32)\n",
    "\n",
    "# Create pytorch datasets\n",
    "trainset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "valset = TensorDataset(X_val_tensor, y_val_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pytorch dataloaders\n",
    "batch_size = 32 \n",
    "train_loader = DataLoader(dataset=trainset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=valset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss: 0.5360277266478125, val loss: 0.3769057646393776\n",
      "Epoch 1, train loss: 0.37201510082309913, val loss: 0.36070685381185535\n",
      "Epoch 2, train loss: 0.350926898995354, val loss: 0.3772550086180369\n",
      "Epoch 3, train loss: 0.3415549395054287, val loss: 0.34388937130570413\n",
      "Epoch 4, train loss: 0.3344634524065813, val loss: 0.34510406237621766\n",
      "Epoch 5, train loss: 0.32887414834281736, val loss: 0.36449053823148125\n",
      "Epoch 6, train loss: 0.32519303964199703, val loss: 0.34444683176481117\n",
      "Epoch 7, train loss: 0.32177047881339177, val loss: 0.34081980778840976\n",
      "Epoch 8, train loss: 0.31904713651017985, val loss: 0.34078088883457885\n",
      "Epoch 9, train loss: 0.3166050994888049, val loss: 0.3472947635682626\n",
      "Epoch 10, train loss: 0.31448905114238884, val loss: 0.34158121569681976\n",
      "Epoch 11, train loss: 0.31252377495006817, val loss: 0.35191721259958325\n",
      "Epoch 12, train loss: 0.3111695528238136, val loss: 0.3403679687087819\n",
      "Epoch 13, train loss: 0.3090308446397818, val loss: 0.34582832857629675\n",
      "Epoch 14, train loss: 0.30716207305554755, val loss: 0.3427771121684441\n",
      "Epoch 15, train loss: 0.306786446580165, val loss: 0.343212859189443\n",
      "Epoch 16, train loss: 0.30489880748980236, val loss: 0.34165547895061094\n",
      "Epoch 17, train loss: 0.3037843753828666, val loss: 0.3478004284034678\n",
      "Early stopping!\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "results = regression_neural_network.regression_network(train_loader, val_loader, X_test_tensor, data.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.6408822819519124\n",
      "MSE: 0.3460020931356468\n",
      "MAE 0.4392821771925936\n",
      "RMSE 0.588219426010096\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print('R2 Score:', results['r2'])\n",
    "print('MSE:', results['mse'])\n",
    "print('MAE', results['mae'])\n",
    "print('RMSE', results['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully at models/pickled_models/regression_neural_net.pt\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "path = 'models/pickled_models/regression_neural_net.pt'\n",
    "save_model(results, path, model_type='pytorch')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
